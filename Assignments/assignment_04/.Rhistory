# Load Chicago boundary
chicagoBoundary <-
st_read("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson") %>%
st_transform('ESRI:102271')
cat("✓ Loaded spatial boundaries\n")
cat("  - Police districts:", nrow(policeDistricts), "\n")
cat("  - Police beats:", nrow(policeBeats), "\n")
#| message: false
# Load from provided data file (downloaded from Chicago open data portal)
treedebris <- read_csv(here("Assignments/assignment_04/data",
"311_Service_Requests_Tree_Debris.csv"))
names(treedebris)
treedebris %>%
summarize(
n_rows = n(),
n_missing_lon = sum(is.na(Longitude)),
n_missing_lat = sum(is.na(Latitude))
)
treedebris_sf <- treedebris %>%
# keep only rows with both coords present
filter(!is.na(Longitude), !is.na(Latitude)) %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
st_transform("ESRI:102271")
# Check the data
cat("\n✓ Loaded treedebris data\n")
cat("  - Number of treedebris:", nrow(treedebris_sf), "\n")
cat("  - CRS:", st_crs(treedebris_sf)$input, "\n")
cat("  - Date range:", min(treedebris_sf$`Completion Date`, na.rm = TRUE), "to",
max(treedebris_sf$`Completion Date`, na.rm = TRUE), "\n")
#| fig-width: 10
#| fig-height: 5
# Simple point map
p1 <- ggplot() +
geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
geom_sf(data = treedebris_sf, color = "#d62828", size = 0.1, alpha = 0.4) +
labs(
title = "Tree Debris Locations",
subtitle = paste0("Chicago 2017, n = ", nrow(treedebris_sf))
)
# Density surface using modern syntax
p2 <- ggplot() +
geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
geom_density_2d_filled(
data = data.frame(st_coordinates(treedebris_sf)),
aes(X, Y),
alpha = 0.7,
bins = 8
) +
scale_fill_viridis_d(
option = "plasma",
direction = -1,
guide = "none"  # Modern ggplot2 syntax (not guide = FALSE)
) +
labs(
title = "Density Surface",
subtitle = "Kernel density estimation"
)
# Combine plots using patchwork (modern approach)
p1 + p2 +
plot_annotation(
title = "Spatial Distribution of Tree Debris in Chicago",
tag_levels = 'A'
)
# Create 500m x 500m grid
fishnet <- st_make_grid(
chicagoBoundary,
cellsize = 500,  # 500 meters per cell
square = TRUE
) %>%
st_sf() %>%
mutate(uniqueID = row_number())
# Keep only cells that intersect Chicago
fishnet <- fishnet[chicagoBoundary, ]
# View basic info
cat("✓ Created fishnet grid\n")
cat("  - Number of cells:", nrow(fishnet), "\n")
cat("  - Cell size:", 500, "x", 500, "meters\n")
cat("  - Cell area:", round(st_area(fishnet[1,])), "square meters\n")
cat("\nTree Debris count distribution:\n")
summary(fishnet$counttreedebris_sf)
cat(
"\nCells with zero tree debris:",
sum(fishnet$counttreedebris_sf == 0), "/", nrow(fishnet),
"(", round(100 * sum(fishnet$counttreedebris_sf == 0) / nrow(fishnet), 1), "%)\n"
)
# Spatial join: which cell contains each tree debris?
treedebris_fishnet <- st_join(treedebris_sf, fishnet, join = st_within) %>%
st_drop_geometry() %>%
group_by(uniqueID) %>%
summarize(counttreedebris_sf = n())
# Join back to fishnet (cells with 0 burglaries will be NA)
fishnet <- fishnet %>%
left_join(treedebris_fishnet, by = "uniqueID") %>%
mutate(counttreedebris_sf = replace_na(counttreedebris_sf, 0))
# Summary statistics
cat("\nTree Debris count distribution:\n")
summary(fishnet$counttreedebris_sf)
cat("\nCells with zero tree debris:",
sum(fishnet$counttreedebris_sf == 0),
"/", nrow(fishnet),
"(", round(100 * sum(fishnet$counttreedebris_sf == 0) / nrow(fishnet), 1), "%)\n")
#| fig-width: 8
#| fig-height: 6
# Visualize aggregated counts
ggplot() +
geom_sf(data = fishnet, aes(fill = counttreedebris_sf), color = NA) +
geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
scale_fill_viridis_c(
name = "Tree Debris",
option = "plasma",
trans = "sqrt",  # Square root for better visualization of skewed data
breaks = c(0, 1, 5, 10, 20, 40)
) +
labs(
title = "Tree Debris Counts by Grid Cell",
subtitle = "500m x 500m cells, Chicago 2013-2015"
) +
theme_crime()
#| message: false
# Convert tree debris to ppp (point pattern) format for spatstat
treedebris_ppp <- as.ppp(
st_coordinates(treedebris_sf),
W = as.owin(st_bbox(chicagoBoundary))
)
# Calculate KDE with 1km bandwidth
kde_treedebris <- density.ppp(
treedebris_ppp,
sigma = 1000,  # 1km bandwidth
edge = TRUE    # Edge correction
)
# Convert to terra raster (modern approach, not raster::raster)
kde_raster <- rast(kde_treedebris)
# Extract KDE values to fishnet cells
fishnet <- fishnet %>%
mutate(
kde_value = terra::extract(
kde_raster,
vect(fishnet),
fun = mean,
na.rm = TRUE
)[, 2]  # Extract just the values column
)
cat("✓ Calculated KDE baseline\n")
#| fig-width: 8
#| fig-height: 6
ggplot() +
geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +
geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
scale_fill_viridis_c(
name = "KDE Value",
option = "plasma"
) +
labs(
title = "Kernel Density Estimation Baseline",
subtitle = "Simple spatial smoothing of tree debris locations"
) +
theme_crime()
#| message: false
# Load from provided data file (downloaded from Chicago open data portal)
potholes <- read_csv(here("Assignments/assignment_04/data",
"311_Service_Requests_Pot_Holes.csv"))
names(potholes)
potholes %>%
summarize(
n_rows = n(),
n_missing_lon = sum(is.na(LONGITUDE)),
n_missing_lat = sum(is.na(LATITUDE))
)
potholes_sf <- potholes %>%
# keep only rows with both coords present
filter(!is.na(LONGITUDE), !is.na(LATITUDE)) %>%
st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326) %>%
st_transform("ESRI:102271")
# Check the data
cat("\n✓ Loaded potholes data\n")
cat("  - Number of potholes:", nrow(potholes_sf), "\n")
cat("  - CRS:", st_crs(potholes_sf)$input, "\n")
cat("  - Date range:", min(potholes_sf$`CREATION DATE`, na.rm = TRUE), "to",
max(potholes_sf$`CREATION DATE`, na.rm = TRUE), "\n")
# Aggregate pothole calls to fishnet
potholes_fishnet <- st_join(potholes_sf, fishnet, join = st_within) %>%
st_drop_geometry() %>%
group_by(uniqueID) %>%
summarize(potholes_sf = n())
# Join to fishnet
fishnet <- fishnet %>%
left_join(potholes_fishnet, by = "uniqueID") %>%
mutate(potholes_sf = replace_na(potholes_sf, 0))
cat("Potholes distribution:\n")
summary(fishnet$potholes_sf)
#| fig-width: 10
#| fig-height: 4
p1 <- ggplot() +
geom_sf(data = fishnet, aes(fill = counttreedebris_sf), color = NA) +
scale_fill_viridis_c(name = "Count", option = "magma") +
labs(title = "Tree Debris 311 Calls") +
theme_crime()
p2 <- ggplot() +
geom_sf(data = fishnet, aes(fill = potholes_sf), color = NA) +
scale_fill_viridis_c(name = "Count", option = "plasma") +
labs(title = "Potholes") +
theme_crime()
p1 + p2 +
plot_annotation(title = "Are tree debris and potholes correlated?")
#| message: false
# Calculate mean distance to 3 nearest potholes
# (Do this OUTSIDE of mutate to avoid sf conflicts)
# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(fishnet))
potholes_coords <- st_coordinates(potholes_sf)
# Check error for k nearest neighbor because coords have NA
colSums(is.na(potholes_coords))
colSums(is.na(fishnet_coords))
#fix invalid rows for Potholes
valid_rows <- complete.cases(potholes_coords)
potholes_coords <- potholes_coords[valid_rows, , drop = FALSE]
# Calculate k nearest neighbors and distances
nn_result <- get.knnx(potholes_coords, fishnet_coords, k = 3)
# Add to fishnet
fishnet <- fishnet %>%
mutate(
potholes_sf.nn = rowMeans(nn_result$nn.dist)
)
cat("✓ Calculated nearest neighbor distances\n")
summary(fishnet$potholes_sf.nn)
# Function to calculate Local Moran's I
calculate_local_morans <- function(data, variable, k = 5) {
# Create spatial weights
coords <- st_coordinates(st_centroid(data))
neighbors <- knn2nb(knearneigh(coords, k = k))
weights <- nb2listw(neighbors, style = "W", zero.policy = TRUE)
# Calculate Local Moran's I
local_moran <- localmoran(data[[variable]], weights)
# Classify clusters
mean_val <- mean(data[[variable]], na.rm = TRUE)
data %>%
mutate(
local_i = local_moran[, 1],
p_value = local_moran[, 5],
is_significant = p_value < 0.05,
moran_class = case_when(
!is_significant ~ "Not Significant",
local_i > 0 & .data[[variable]] > mean_val ~ "High-High",
local_i > 0 & .data[[variable]] <= mean_val ~ "Low-Low",
local_i < 0 & .data[[variable]] > mean_val ~ "High-Low",
local_i < 0 & .data[[variable]] <= mean_val ~ "Low-High",
TRUE ~ "Not Significant"
)
)
}
# Apply to Potholes
fishnet <- calculate_local_morans(fishnet, "potholes_sf", k = 5)
#| fig-width: 8
#| fig-height: 6
# Visualize hot spots
ggplot() +
geom_sf(
data = fishnet,
aes(fill = moran_class),
color = NA
) +
scale_fill_manual(
values = c(
"High-High" = "#d7191c",
"High-Low" = "#fdae61",
"Low-High" = "#abd9e9",
"Low-Low" = "#2c7bb6",
"Not Significant" = "gray90"
),
name = "Cluster Type"
) +
labs(
title = "Local Moran's I: Potholes Clusters",
subtitle = "High-High = Hot spots of disorder"
) +
theme_crime()
# Get centroids of "High-High" cells (hot spots)
hotspots <- fishnet %>%
filter(moran_class == "High-High") %>%
st_centroid()
# Calculate distance from each cell to nearest hot spot
if (nrow(hotspots) > 0) {
fishnet <- fishnet %>%
mutate(
dist_to_hotspot = as.numeric(
st_distance(st_centroid(fishnet), hotspots %>% st_union())
)
)
cat("✓ Calculated distance to pothole hot spots\n")
cat("  - Number of hot spot cells:", nrow(hotspots), "\n")
} else {
fishnet <- fishnet %>%
mutate(dist_to_hotspot = 0)
cat("⚠ No significant hot spots found\n")
}
# Join district information to fishnet
fishnet <- st_join(
fishnet,
policeDistricts,
join = st_within,
left = TRUE
) %>%
filter(!is.na(District))  # Remove cells outside districts
cat("✓ Joined police districts\n")
cat("  - Districts:", length(unique(fishnet$District)), "\n")
cat("  - Cells:", nrow(fishnet), "\n")
# Create clean modeling dataset
fishnet_model <- fishnet %>%
st_drop_geometry() %>%
dplyr::select(
uniqueID,
District,
counttreedebris_sf,
potholes_sf,
potholes_sf.nn,
dist_to_hotspot
) %>%
na.omit()  # Remove any remaining NAs
cat("✓ Prepared modeling data\n")
cat("  - Observations:", nrow(fishnet_model), "\n")
cat("  - Variables:", ncol(fishnet_model), "\n")
# Fit Poisson regression
model_poisson <- glm(
counttreedebris_sf ~ potholes_sf + potholes_sf.nn +
dist_to_hotspot,
data = fishnet_model,
family = "poisson"
)
# Summary
summary(model_poisson)
# Calculate dispersion parameter
dispersion <- sum(residuals(model_poisson, type = "pearson")^2) /
model_poisson$df.residual
cat("Dispersion parameter:", round(dispersion, 2), "\n")
cat("Rule of thumb: >1.5 suggests overdispersion\n")
if (dispersion > 1.5) {
cat("⚠ Overdispersion detected! Consider Negative Binomial model.\n")
} else {
cat("✓ Dispersion looks okay for Poisson model.\n")
}
# Fit Negative Binomial model
model_nb <- glm.nb(
counttreedebris_sf ~ potholes_sf + potholes_sf.nn +
dist_to_hotspot,
data = fishnet_model
)
# Summary
summary(model_nb)
# Compare AIC (lower is better)
cat("\nModel Comparison:\n")
cat("Poisson AIC:", round(AIC(model_poisson), 1), "\n")
cat("Negative Binomial AIC:", round(AIC(model_nb), 1), "\n")
# Get unique districts
districts <- unique(fishnet_model$District)
cv_results <- tibble()
cat("Running LOGO Cross-Validation...\n")
for (i in seq_along(districts)) {
test_district <- districts[i]
# Split data
train_data <- fishnet_model %>% filter(District != test_district)
test_data <- fishnet_model %>% filter(District == test_district)
# Fit model on training data
model_cv <- glm.nb(
counttreedebris_sf ~ potholes_sf + potholes_sf.nn +
dist_to_hotspot,
data = train_data
)
# Predict on test data
test_data <- test_data %>%
mutate(
prediction = predict(model_cv, test_data, type = "response")
)
# Calculate metrics
mae <- mean(abs(test_data$counttreedebris_sf - test_data$prediction))
rmse <- sqrt(mean((test_data$counttreedebris_sf - test_data$prediction)^2))
# Store results
cv_results <- bind_rows(
cv_results,
tibble(
fold = i,
test_district = test_district,
n_test = nrow(test_data),
mae = mae,
rmse = rmse
)
)
cat("  Fold", i, "/", length(districts), "- District", test_district,
"- MAE:", round(mae, 2), "\n")
}
# Overall results
cat("\n✓ Cross-Validation Complete\n")
cat("Mean MAE:", round(mean(cv_results$mae), 2), "\n")
cat("Mean RMSE:", round(mean(cv_results$rmse), 2), "\n")
# Show results
cv_results %>%
arrange(desc(mae)) %>%
kable(
digits = 2,
caption = "LOGO CV Results by District"
) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Fit final model on all data
final_model <- glm.nb(
counttreedebris_sf ~ potholes_sf + potholes_sf.nn +
dist_to_hotspot,
data = fishnet_model
)
# Add predictions back to fishnet
fishnet <- fishnet %>%
mutate(
prediction_nb = predict(final_model, fishnet_model, type = "response")[match(uniqueID, fishnet_model$uniqueID)]
)
# Also add KDE predictions (normalize to same scale as counts)
kde_sum <- sum(fishnet$kde_value, na.rm = TRUE)
count_sum <- sum(fishnet$counttreedebris_sf, na.rm = TRUE)
fishnet <- fishnet %>%
mutate(
prediction_kde = (kde_value / kde_sum) * count_sum
)
#| fig-width: 12
#| fig-height: 4
# Create three maps
p1 <- ggplot() +
geom_sf(data = fishnet, aes(fill = counttreedebris_sf), color = NA) +
scale_fill_viridis_c(name = "Count", option = "plasma", limits = c(0, 15)) +
labs(title = "Actual Tree Debris") +
theme_crime()
p2 <- ggplot() +
geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +
scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
labs(title = "Model Predictions (Neg. Binomial)") +
theme_crime()
p3 <- ggplot() +
geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +
scale_fill_viridis_c(name = "Predicted", option = "plasma", limits = c(0, 15)) +
labs(title = "KDE Baseline Predictions") +
theme_crime()
p1 + p2 + p3 +
plot_annotation(
title = "Actual vs. Predicted Tree Debris",
subtitle = "Does our complex model outperform simple KDE?"
)
# Calculate performance metrics
comparison <- fishnet %>%
st_drop_geometry() %>%
filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%
summarize(
model_mae = mean(abs(counttreedebris_sf - prediction_nb)),
model_rmse = sqrt(mean((counttreedebris_sf - prediction_nb)^2)),
kde_mae = mean(abs(counttreedebris_sf - prediction_kde)),
kde_rmse = sqrt(mean((counttreedebris_sf - prediction_kde)^2))
)
comparison %>%
pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
separate(metric, into = c("approach", "metric"), sep = "_") %>%
pivot_wider(names_from = metric, values_from = value) %>%
kable(
digits = 2,
caption = "Model Performance Comparison"
) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
#| fig-width: 10
#| fig-height: 5
# Calculate errors
fishnet <- fishnet %>%
mutate(
error_nb = counttreedebris_sf - prediction_nb,
error_kde = counttreedebris_sf - prediction_kde,
abs_error_nb = abs(error_nb),
abs_error_kde = abs(error_kde)
)
# Map errors
p1 <- ggplot() +
geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +
scale_fill_gradient2(
name = "Error",
low = "#2166ac", mid = "white", high = "#b2182b",
midpoint = 0,
limits = c(-10, 10)
) +
labs(title = "Model Errors (Actual - Predicted)") +
theme_crime()
p2 <- ggplot() +
geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +
scale_fill_viridis_c(name = "Abs. Error", option = "magma") +
labs(title = "Absolute Model Errors") +
theme_crime()
p1 + p2
# Create nice summary table
model_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%
mutate(
across(where(is.numeric), ~round(., 3))
)
model_summary %>%
kable(
caption = "Final Negative Binomial Model Coefficients (Exponentiated)",
col.names = c("Variable", "Rate Ratio", "Std. Error", "Z", "P-Value")
) %>%
kable_styling(bootstrap_options = c("striped", "hover")) %>%
footnote(
general = "Rate ratios > 1 indicate positive association with tree debris counts."
)
file.exists("Assignments/assignment_04/assignment4.html")
list.files("Assignments/assignment_04")
dir.exists("docs")
dir.exists("docs/Assignments")
dir.exists("docs/Assignments/assignment_04")
dir.create("docs/Assignments/assignment_04", recursive = TRUE, showWarnings = FALSE)
file.exists("Assignments/assignment_04/assignment4.html")
quarto::quarto_render("Assignments/assignment_04/assignment4.qmd")
file.exists("Assignments/assignment_04/assignment4.html")
file.exists("Assignments/assignment_04/assignment4.html")
